<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Green Milk Tea Shop Classifier</title>
  <link rel="stylesheet" href="style.css?v=8">
</head>
<body>

  <main class="section">
    <div class="container">

      <div class="project-row">

        <figure class="project-figure">
          <img
            src="./images/esp32-setup.png"
            alt="ESP32 setup"
            class="project-img"
          >
        </figure>

        <div class="project-text">
          
          <h1 class="project-title">Green Milk Tea Shop Classifier</h1>
          <p class="muted">
            ESP32-based system integrating five sensors: color, total dissolved solids (TDS),
            turbidity, temperature, and pH. The apparatus was used to collect sensor data from
            green milk tea samples across five different retail stores.
          </p>

          <h2 class="project-section">Objective</h2>
          <p class="muted">
            The objective of this project was to use a sensor dataâ€“driven machine learning
            approach to distinguish between green milk tea samples using the k-nearest neighbors (kNN) algorithm.
          </p>

          <h2 class="project-section">Methods</h2>
          <p class="muted">
             To minimize variability, all green milk tea samples were ordered with zero sugar and no ice. 
             For each sample, sensor measurements were recorded using the same apparatus and conditions. 
             With the exception of total dissolved solids (TDS) and temperature, all sensor readings were taken as raw values. 
             Although readings from the F1-F8 spectral channels, which span approximately 415-680nm, were sample-specific and valuable, they were excluded due to the risk of overfitting the kNN model. 
             Temperature readings were also excluded due to low variability between samples and treated as a noise factor. 

             A kNN classifier is advantageous when working with small datasets and does not require explicit model training. 
             All remaining features were normalized to ensure equal weighting during kNN classification. 
            
             Model performance was evaluated using a classification report.
          </p>
          
        </div>

      </div>

    </div>
  </main>

</body>
</html>
